
Priyansh (B19CSE067) and Praneet Thakur (B19CSE066)

### Dependencies
* python >= 3.6.8
* tensorflow >=1.12.0  / pytorch >= 1.1.0
* cython >=0.29.2
* numpy >= 1.14.3
* scipy >= 1.1.0
* scikit-learn >= 0.19.1
* pyyaml >= 3.12
* g++ >= 5.4.0
* openmp >= 4.0


## Netlist-to-graph Conversion

### Datasets
The `Interconnected-Modules` contains the dataset. The dataset contains 37 designs. Five different sub-circuit classes exist in the dataset, i.e., adders, multipliers, control logic, subtractors, and comparators. All the designs are synthesized using Synopsys Design Compiler with Global Foundries 65nm LPe.

When creating a dataset, the files used for training, validation or testing were identified. To split files into Test/Train/validate, the files were named accordingly. All files were named as follows: [Test|Train|Validate]_*.v


### Conversion to Graphs
**Scripts**

The following scripts are required for the conversion:  
`./Parsers/TheCircuit.pm`: a Perl module we create to ease circuit's parsing. This module is required by the parser `Parsers/netlist_to_graph_re.pl`

`./Parsers/netlist_to_graph_re.pl`: a Perl script that reads all of the designs (Synthesized Gate-level Netlists) in a given dataset and converts the dataset into a single graph. It assigns unique numerical IDs (0 to N-1) to the nodes (gates). N represents the total number of nodes (gates) in the dataset. The list of nodes in the training set will be dumped in `tr.txt`. The list of nodes in the testing set will be dumped in `te.txt`. The list of nodes in the validation set will be dumped in `va.txt`. The extracted features will be dumped in `feat.txt`. The existence of an edge i between two vertices u and v is represented by the entry of ith line in `row.txt` (representing u's ID) and the entry of the ith line in `col.txt` (representing v's ID). The `row_tr.txt` and `col_tr.txt` are created to identify the edges exclusive to the training set.

`./Parsers/graph_parser.py`: a Python script that processes the files created by the Perl parser and generates the files required by GraphSAINT. The more details on the file structure created can be found in detail in the graphSAINT repository.

**Running the Conversion code**   
1) Create and activate conda environment with the required dependencies or a virtual environment or as per choice.

2) Modify line 6 in `./Parsers/netlist_to_graph_re.pl` and place the full path to `theCircuit.pm`.

3) To perform the conversion do: 
```sh 
    $ perl <path to netlist_to_graph_re.pl> -i <directory path in which to save the graph data> > log.txt
    $ python graph_parser.py //the file should be run from inside directory in which the graph data is saved
```    

## Node Classification (can also be referred from graphSAINT directory)
We have used the TensorFlow implementation of GraphSAINT. The graphSAINT code is already provided or you can clone it.

To install GraphSAINT:
```sh
$ git clone https://github.com/GraphSAINT/GraphSAINT.git
$ cd GraphSAINT
```
To Compilation (done only once)
```sh
$ python graphsaint/setup.py build_ext --inplace
```
Launch Node Classification:
```sh
$ python -m graphsaint.tensorflow_version.train --data_prefix <path to directory with graph data generated by graph_parser.py> --train_config <path to the .yml file(an example is there) > --gpu -1 > log_training.txt
```
`.yml` contains the hyperparameters used in the GNN.






